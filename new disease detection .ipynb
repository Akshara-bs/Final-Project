{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObByGDHqxSaD5aQC+DBO8e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":38,"metadata":{"id":"_n7oTT6-WNE2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740694409644,"user_tz":0,"elapsed":1650,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"57dc1c0a-40ca-4e6a-afb0-c15d7989103f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns"],"metadata":{"id":"A5y-tEbabpjX","executionInfo":{"status":"ok","timestamp":1740694410867,"user_tz":0,"elapsed":2,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Define dataset paths\n","dataset_path = \"/content/drive/MyDrive/cassava_dataset\"\n","image_folder = os.path.join(dataset_path, \"train_images\")\n","csv_file = os.path.join(dataset_path, \"train.csv\")\n","\n","# Load CSV file\n","df = pd.read_csv(csv_file)\n","\n","\n","# Check the first few rows\n","print(df.head())\n","\n","print(df['image_id'].head())  # Check the first few filenames\n","\n","# Check class distribution\n","sns.countplot(x=df['label'])\n","plt.title(\"Class Distribution\")\n","plt.show()\n"],"metadata":{"id":"NcPPXfixbu-Y","colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"status":"ok","timestamp":1740694414745,"user_tz":0,"elapsed":363,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"5e83804d-ec1c-4ab0-957f-c54067667874"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["         image_id  label\n","0  1000015157.jpg      0\n","1  1000201771.jpg      3\n","2   100042118.jpg      1\n","3  1000723321.jpg      1\n","4  1000812911.jpg      3\n","0    1000015157.jpg\n","1    1000201771.jpg\n","2     100042118.jpg\n","3    1000723321.jpg\n","4    1000812911.jpg\n","Name: image_id, dtype: object\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["\n","image_folder = \"/content/drive/MyDrive/cassava_dataset/train_images\"\n","\n","if os.path.exists(image_folder):\n","    print(\"Image folder exists\")\n","    print(\"Sample images in directory:\", os.listdir(image_folder)[:10])  # Show first 10 images\n","else:\n","    print(\"Image folder does NOT exist! Check your Google Drive path.\")\n","\n","print(os.listdir(image_folder)[:10])  # Show the first 10 image names\n"],"metadata":{"id":"q9fO1f0UnqXZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740694418297,"user_tz":0,"elapsed":570,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"428a66ba-94b3-4013-bb5d-a4c29fa8fdb2"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Image folder exists\n","Sample images in directory: ['805835204.jpg', '808870213.jpg', '807190211.jpg', '80998969.jpg', '807555228.jpg', '806670613.jpg', '808606006.jpg', '804903970.jpg', '809489252.jpg', '807063038.jpg']\n","['805835204.jpg', '808870213.jpg', '807190211.jpg', '80998969.jpg', '807555228.jpg', '806670613.jpg', '808606006.jpg', '804903970.jpg', '809489252.jpg', '807063038.jpg']\n"]}]},{"cell_type":"code","source":["\n","\n","# Define paths\n","csv_path = \"/content/drive/MyDrive/cassava_dataset/train.csv\"\n","image_folder = \"/content/drive/MyDrive/cassava_dataset/train_images\"\n","\n","# Load train.csv\n","df = pd.read_csv(csv_path)\n","\n","# Get lists of image names\n","csv_images = set(df['image_id'])  # Images listed in CSV\n","folder_images = set(os.listdir(image_folder))  # Images in train_images folder\n","\n","# Identify missing and extra images\n","missing_images = csv_images - folder_images  # In CSV but not in folder\n","extra_images = folder_images - csv_images  # In folder but not in CSV\n","\n","# Print results\n","print(f\"Total images in CSV: {len(csv_images)}\")\n","print(f\"Total images in folder: {len(folder_images)}\")\n","print(f\"Missing images (in CSV but not in folder): {len(missing_images)}\")\n","print(f\"Extra images (in folder but not in CSV): {len(extra_images)}\")\n"],"metadata":{"id":"p6xYpjw9xwGt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740694419729,"user_tz":0,"elapsed":360,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"faebd909-3f88-4033-e466-b9abe4d6ac23"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Total images in CSV: 21397\n","Total images in folder: 17938\n","Missing images (in CSV but not in folder): 3459\n","Extra images (in folder but not in CSV): 0\n"]}]},{"cell_type":"code","source":["# Remove rows in df where images are missing\n","df = df[~df['image_id'].isin(missing_images)]\n","\n","# Save cleaned CSV (optional, for future use)\n","cleaned_csv_path = \"/content/drive/MyDrive/cassava_dataset/train_cleaned.csv\"\n","df.to_csv(cleaned_csv_path, index=False)\n","\n","print(f\"Updated dataset size: {len(df)}\")\n"],"metadata":{"id":"IDx8Y9aqyAHY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740694421947,"user_tz":0,"elapsed":54,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"7413c67e-4feb-4d22-d0bf-11ae66c359cf"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated dataset size: 17938\n"]}]},{"cell_type":"code","source":["for img in extra_images:\n","    img_path = os.path.join(image_folder, img)\n","    os.remove(img_path)  # Delete extra image\n","\n","print(\"Extra images removed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9qtBjJET3kVw","executionInfo":{"status":"ok","timestamp":1740694424301,"user_tz":0,"elapsed":21,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"4dd918a3-bc0e-40ae-e9dd-efbdb5d9fbe5"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Extra images removed successfully!\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Define constants\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","\n","# Define paths\n","dataset_path = \"/content/drive/MyDrive/cassava_dataset\"\n","csv_path = os.path.join(dataset_path, \"train.csv\")\n","image_folder = os.path.join(dataset_path, \"train_images\")\n","\n","# Load dataset\n","df = pd.read_csv(csv_path)\n","\n","# Get actual image filenames from the folder\n","available_images = set(os.listdir(image_folder))\n","\n","# Remove rows where images are missing\n","df = df[df['image_id'].isin(available_images)].reset_index(drop=True)\n","\n","# Print dataset stats\n","print(f\"Total images in CSV (after cleaning): {len(df)}\")\n","print(f\"Total images available in folder: {len(available_images)}\")\n","\n","\n","# Function to preprocess images\n","def preprocess_image(img_path):\n","    try:\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            raise Exception(\"Corrupt Image\")\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert BGR to RGB\n","        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) # Resize to 224x224\n","        img = img / 255.0  # Normalize pixel values to [0,1]\n","        return img\n","    except:\n","        print(f\"Warning: Could not read image {img_path}\")\n","        return np.zeros((IMG_SIZE, IMG_SIZE, 3))  # Return blank image\n","\n","# Split dataset into train, validation, test\n","df_train, df_temp = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n","df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['label'], random_state=42)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPDLyQdrMs3S","executionInfo":{"status":"ok","timestamp":1740694427158,"user_tz":0,"elapsed":418,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"7b299e27-000a-4a66-fc1b-dce0157a2d7d"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Total images in CSV (after cleaning): 17938\n","Total images available in folder: 17938\n"]}]},{"cell_type":"code","source":["# Define Data Augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,          # Normalize pixel values\n","    rotation_range=30,       # Random rotation (0-30 degrees)\n","    width_shift_range=0.2,   # Horizontal shift (up to 20% of width)\n","    height_shift_range=0.2,  # Vertical shift (up to 20% of height)\n","    shear_range=0.2,         # Shearing transformation (distorts shape)\n","    zoom_range=0.2,          # Random zoom\n","    horizontal_flip=True,    # Randomly flip images horizontally\n","    fill_mode='nearest'      # Fill missing pixels after transformation\n",")\n","\n","#Validation & Test Preprocessing\n","val_datagen = ImageDataGenerator(rescale=1./255)  # Only rescaling for validation & test\n","\n","# Convert 'label' column to string type\n","df_train['label'] = df_train['label'].astype(str)\n","df_val['label'] = df_val['label'].astype(str)\n","df_test['label'] = df_test['label'].astype(str)\n","\n","# Create Data Generators\n","#train generator(with augumentation)\n","train_generator = train_datagen.flow_from_dataframe(\n","    df_train, directory=image_folder, x_col=\"image_id\", y_col=\"label\",\n","    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode=\"sparse\"\n",")\n","\n","#Validation Generator-Only rescales images (no augmentation)\n","val_generator = val_datagen.flow_from_dataframe(\n","    df_val, directory=image_folder, x_col=\"image_id\", y_col=\"label\",\n","    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode=\"sparse\"\n",")\n","\n","#Test Generator (For Final Evaluation)\n","test_generator = val_datagen.flow_from_dataframe(\n","    df_test, directory=image_folder, x_col=\"image_id\", y_col=\"label\",\n","    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode=\"sparse\",\n","    shuffle=False  # No need to shuffle test data\n",")\n","\n","# Print dataset sizes\n","print(f\"Train size: {len(df_train)}, Validation size: {len(df_val)}, Test size: {len(df_test)}\")\n","print(\" Data preprocessing & augmentation completed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5NGccV5ZsL6","executionInfo":{"status":"ok","timestamp":1740694434318,"user_tz":0,"elapsed":2560,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"6cad0a94-8810-4f8b-d22c-8c1dc3948b0a"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 12556 validated image filenames belonging to 5 classes.\n","Found 2691 validated image filenames belonging to 5 classes.\n","Found 2691 validated image filenames belonging to 5 classes.\n","Train size: 12556, Validation size: 2691, Test size: 2691\n"," Data preprocessing & augmentation completed successfully!\n"]}]},{"cell_type":"code","source":["# Define custom CNN model\n","def build_custom_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=len(df['label'].unique())):\n","    model = Sequential([\n","        Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Conv2D(64, (3,3), activation='relu', padding='same'),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Conv2D(128, (3,3), activation='relu', padding='same'),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Conv2D(256, (3,3), activation='relu', padding='same'),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(256, activation='relu'),\n","        Dropout(0.5),\n","        Dense(num_classes, activation='softmax')  # Multi-class classification\n","    ])\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss=\"sparse_categorical_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","\n","    return model\n","\n","# Create model\n","model = build_custom_cnn()\n","model.summary()\n","\n","# Define callbacks\n","callbacks = [\n","    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\"),\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, verbose=1, mode=\"min\"),\n","    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, restore_best_weights=True)\n","]\n","\n","# Train model\n","history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=EPOCHS,\n","    callbacks=callbacks\n",")\n","\n","# Evaluate model on test set\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n","\n","# Save final model\n","model.save(\"cassava_custom_cnn.h5\")\n","print(\"Model saved successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lnBHGfoNZ-Hx","executionInfo":{"status":"ok","timestamp":1740699875617,"user_tz":0,"elapsed":5438536,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"882da335-d87d-46c4-9b9d-1a07044ca206"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m25,690,624\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │           \u001b[38;5;34m1,285\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,624</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,213,573\u001b[0m (100.00 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,213,573</span> (100.00 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,212,613\u001b[0m (99.99 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,212,613</span> (99.99 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4281 - loss: 10.8929"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 2s/step - accuracy: 0.4282 - loss: 10.8796 - val_accuracy: 0.6132 - val_loss: 1.4436 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - accuracy: 0.5865 - loss: 1.3315"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 632ms/step - accuracy: 0.5866 - loss: 1.3314 - val_accuracy: 0.6150 - val_loss: 1.1831 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.6056 - loss: 1.2016"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 621ms/step - accuracy: 0.6056 - loss: 1.2016 - val_accuracy: 0.6150 - val_loss: 1.0812 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 618ms/step - accuracy: 0.6183 - loss: 1.1250 - val_accuracy: 0.6150 - val_loss: 1.2410 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.6100 - loss: 1.0865"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 620ms/step - accuracy: 0.6101 - loss: 1.0865 - val_accuracy: 0.6150 - val_loss: 1.0300 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 614ms/step - accuracy: 0.6154 - loss: 1.0554 - val_accuracy: 0.6150 - val_loss: 1.1137 - learning_rate: 0.0010\n","Epoch 7/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6104 - loss: 1.0861"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 618ms/step - accuracy: 0.6104 - loss: 1.0861 - val_accuracy: 0.6150 - val_loss: 1.0254 - learning_rate: 0.0010\n","Epoch 8/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 622ms/step - accuracy: 0.6214 - loss: 1.0329 - val_accuracy: 0.6139 - val_loss: 1.2209 - learning_rate: 0.0010\n","Epoch 9/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 618ms/step - accuracy: 0.6167 - loss: 1.0129 - val_accuracy: 0.6150 - val_loss: 1.0605 - learning_rate: 0.0010\n","Epoch 10/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.6164 - loss: 1.0119"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 618ms/step - accuracy: 0.6164 - loss: 1.0120 - val_accuracy: 0.6150 - val_loss: 1.0134 - learning_rate: 0.0010\n","Epoch 11/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 604ms/step - accuracy: 0.6074 - loss: 1.0277 - val_accuracy: 0.6150 - val_loss: 1.1714 - learning_rate: 0.0010\n","Epoch 12/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.6194 - loss: 0.9941"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 620ms/step - accuracy: 0.6194 - loss: 0.9941 - val_accuracy: 0.6150 - val_loss: 1.0055 - learning_rate: 0.0010\n","Epoch 13/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 608ms/step - accuracy: 0.6107 - loss: 1.0095 - val_accuracy: 0.6150 - val_loss: 1.2884 - learning_rate: 0.0010\n","Epoch 14/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 607ms/step - accuracy: 0.6153 - loss: 1.0054 - val_accuracy: 0.6150 - val_loss: 1.0627 - learning_rate: 0.0010\n","Epoch 15/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6177 - loss: 0.9898\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 612ms/step - accuracy: 0.6177 - loss: 0.9898 - val_accuracy: 0.6150 - val_loss: 1.1025 - learning_rate: 0.0010\n","Epoch 16/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - accuracy: 0.6099 - loss: 0.9504"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 606ms/step - accuracy: 0.6099 - loss: 0.9503 - val_accuracy: 0.6150 - val_loss: 0.8711 - learning_rate: 2.0000e-04\n","Epoch 17/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 610ms/step - accuracy: 0.6140 - loss: 0.9113 - val_accuracy: 0.6150 - val_loss: 1.0716 - learning_rate: 2.0000e-04\n","Epoch 18/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 617ms/step - accuracy: 0.6174 - loss: 0.9044 - val_accuracy: 0.6150 - val_loss: 0.8734 - learning_rate: 2.0000e-04\n","Epoch 19/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.6130 - loss: 0.9127\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 606ms/step - accuracy: 0.6130 - loss: 0.9127 - val_accuracy: 0.6150 - val_loss: 0.8871 - learning_rate: 2.0000e-04\n","Epoch 20/20\n","\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6122 - loss: 0.8884"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 616ms/step - accuracy: 0.6122 - loss: 0.8884 - val_accuracy: 0.6150 - val_loss: 0.8694 - learning_rate: 4.0000e-05\n","Restoring model weights from the end of the best epoch: 20.\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 299ms/step - accuracy: 0.6193 - loss: 0.8832\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 61.46%\n","Model saved successfully!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XSCtDMAnZ-EV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y0KhPhqvZ-Bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-XeByoGiZ9-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BlFE7q3fZ97U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Define constants\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","\n","# Define paths\n","dataset_path = \"/content/drive/MyDrive/cassava_dataset\"\n","csv_path = os.path.join(dataset_path, \"train.csv\")\n","image_folder = os.path.join(dataset_path, \"train_images\")\n","\n","# Load dataset\n","df = pd.read_csv(csv_path)\n","\n","# Get actual image filenames from the folder\n","available_images = set(os.listdir(image_folder))\n","\n","# Remove rows where images are missing\n","df = df[df['image_id'].isin(available_images)].reset_index(drop=True)\n","\n","# Print dataset stats\n","print(f\"Total images in CSV (after cleaning): {len(df)}\")\n","print(f\"Total images available in folder: {len(available_images)}\")\n","\n","# Function to preprocess images\n","def preprocess_image(img_path):\n","    try:\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            raise Exception(\"Corrupt Image\")\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","        img = img / 255.0  # Normalize\n","        return img\n","    except:\n","        print(f\"Warning: Could not read image {img_path}\")\n","        return np.zeros((IMG_SIZE, IMG_SIZE, 3))  # Return blank image\n","\n","# Function to generate batches of data\n","class CassavaDataGenerator:\n","    def __init__(self, df, image_folder, batch_size=BATCH_SIZE):\n","        self.df = df\n","        self.image_folder = image_folder\n","        self.batch_size = batch_size\n","        self.indexes = np.arange(len(df))\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.df) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        batch_indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n","        batch_df = self.df.iloc[batch_indexes]\n","\n","        batch_images = np.array([preprocess_image(os.path.join(self.image_folder, img)) for img in batch_df['image_id']])\n","        batch_labels = np.array(batch_df['label'])\n","\n","        return batch_images, batch_labels\n","\n","# Split dataset into train, validation, test\n","df_train, df_temp = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n","df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['label'], random_state=42)\n","\n","# Create data generators\n","train_generator = CassavaDataGenerator(df_train, image_folder, BATCH_SIZE)\n","val_generator = CassavaDataGenerator(df_val, image_folder, BATCH_SIZE)\n","test_generator = CassavaDataGenerator(df_test, image_folder, BATCH_SIZE)\n","\n","# Print dataset sizes\n","print(f\"Train size: {len(df_train)}, Validation size: {len(df_val)}, Test size: {len(df_test)}\")\n","print(\"Dataset preprocessing completed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugWPw1_2-lZK","executionInfo":{"status":"ok","timestamp":1740686656240,"user_tz":0,"elapsed":287,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"d4363fa2-ecac-4fe9-e2bd-2754e1d7adfb"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Total images in CSV (after cleaning): 17938\n","Total images available in folder: 17938\n","Train size: 12556, Validation size: 2691, Test size: 2691\n","Dataset preprocessing completed successfully!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"V6-_H3MjGoHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Isd-_18kGoEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m1MvH3KsGoBY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Import libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","\n","# Define constants\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","dataset_path = \"/content/drive/MyDrive/cassava_dataset\"\n","csv_path = os.path.join(dataset_path, \"train.csv\")\n","image_folder = os.path.join(dataset_path, \"train_images\")\n","\n","# Load dataset\n","df = pd.read_csv(csv_path)\n","\n","# Filter missing images\n","available_images = set(os.listdir(image_folder))\n","df = df[df['image_id'].isin(available_images)].reset_index(drop=True)\n","\n","# Print dataset stats\n","print(f\"Total images in dataset (after cleaning): {len(df)}\")\n","\n","# Data split (train, validation, test)\n","df_train, df_temp = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n","df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['label'], random_state=42)\n","\n","# Define data generators with augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0/255.0,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n",")\n","\n","val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n","\n","# Create image data generators\n","train_generator = train_datagen.flow_from_dataframe(\n","    df_train, directory=image_folder, x_col=\"image_id\", y_col=\"label\",\n","    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode=\"sparse\",\n","    dtype='float32'\n",")\n","\n","val_generator = val_test_datagen.flow_from_dataframe(\n","    df_val, directory=image_folder, x_col=\"image_id\", y_col=\"label\",\n","    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode=\"sparse\",\n","    dtype='float32'\n",")\n","\n","test_generator = val_test_datagen.flow_from_dataframe(\n","    df_test, directory=image_folder, x_col=\"image_id\", y_col=\"label\",\n","    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode=\"sparse\", shuffle=False,\n","    dtype='float32'\n",")\n","\n","# Define custom CNN model\n","def build_custom_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=len(df['label'].unique())):\n","    model = Sequential([\n","        Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Conv2D(64, (3,3), activation='relu', padding='same'),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Conv2D(128, (3,3), activation='relu', padding='same'),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Conv2D(256, (3,3), activation='relu', padding='same'),\n","        BatchNormalization(),\n","        MaxPooling2D((2,2)),\n","\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(256, activation='relu'),\n","        Dropout(0.5),\n","        Dense(num_classes, activation='softmax')  # Multi-class classification\n","    ])\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss=\"sparse_categorical_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","\n","    return model\n","\n","# Create model\n","model = build_custom_cnn()\n","model.summary()\n","\n","# Define callbacks\n","callbacks = [\n","    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\"),\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, verbose=1, mode=\"min\"),\n","    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, restore_best_weights=True)\n","]\n","\n","# Train model\n","history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=EPOCHS,\n","    callbacks=callbacks\n",")\n","\n","# Evaluate model on test set\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n","\n","# Save final model\n","model.save(\"cassava_custom_cnn.h5\")\n","print(\"Model saved successfully!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"Ady-fINl-5rX","executionInfo":{"status":"error","timestamp":1740687518262,"user_tz":0,"elapsed":380,"user":{"displayName":"Akshara B. S","userId":"05170073383062320773"}},"outputId":"6a12a475-2654-4733-be35-87e3a6d0b9e5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Total images in dataset (after cleaning): 17938\n"]},{"output_type":"error","ename":"TypeError","evalue":"If class_mode=\"sparse\", y_col=\"label\" column values must be strings.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-c14907ba5042>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Create image data generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m train_generator = train_datagen.flow_from_dataframe(\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m             )\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         return DataFrameIterator(\n\u001b[0m\u001b[1;32m   1209\u001b[0m             \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;31m# check that inputs match the required class_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         if (\n\u001b[1;32m    753\u001b[0m             \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparse\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    820\u001b[0m                     \u001b[0;34m'If class_mode=\"{}\", y_col=\"{}\" column '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                     \u001b[0;34m\"values must be strings.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: If class_mode=\"sparse\", y_col=\"label\" column values must be strings."]}]},{"cell_type":"code","source":[],"metadata":{"id":"BU0YXjX1-5np"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N-Fy_WaO-5a_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DiYQWsJb-5Xg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Oisu8gDs-5UX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PflJcApgcUhk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MyHpGFI8cUeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3wb8Q5B_cUa-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3EIgwhwWcUX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GjcOfNHKcUUx"},"execution_count":null,"outputs":[]}]}